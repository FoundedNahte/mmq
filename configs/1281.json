[
  {
    "model_part": "LLM",
    "layer_group": "MIDDLE",
    "layer_type": "ATTENTION",
    "num_bits": 4
  }
]