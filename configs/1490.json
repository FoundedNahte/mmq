[
  {
    "model_part": "LLM",
    "layer_group": "ALL",
    "layer_type": "ATTENTION",
    "num_bits": 3
  }
]