{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2252dab7-667f-454b-bba1-6a75f57aec63",
   "metadata": {},
   "source": [
    "# Blip2 COCO Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f543991-f107-4ae1-9988-ec55ff36af40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851687413df746eaa692a1bda6492c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "from datasets import COCODataset\n",
    "from datasets import COCODataset\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load BLIP-2 model and processor\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "\n",
    "# Ensure the model is on the correct device\n",
    "model = model.to(device)\n",
    "\n",
    "# Load COCO dataset\n",
    "coco_dataset = COCODataset(ann_file='./data/coco/annotations/captions_val2017.json',\n",
    "                           img_dir='./data/coco/val2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36001a9a-7ab2-4978-bd25-5bfacb1b7db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coco_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c57227e-4ed7-4776-821e-b3222b46dd68",
   "metadata": {},
   "source": [
    "## Collect Inference Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe866692-f447-431f-8e3d-2a37df47f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def eval_model(qmodel, results_file=\"./results/inference.json\"):\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, min(1000, len(coco_dataset)))):\n",
    "        image, _ = coco_dataset[i]\n",
    "        \n",
    "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            out = qmodel.generate(**inputs)\n",
    "        \n",
    "        caption = processor.decode(out[0], skip_special_tokens=True).strip()\n",
    "        \n",
    "        image_id = coco_dataset.ids[i]\n",
    "        results.append({\"image_id\": image_id, \"caption\": caption})\n",
    "\n",
    "    with open('./results/coco_results.json', 'w') as f:\n",
    "        json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd1756a-0c5f-482b-a82d-eee5584e1474",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for i in tqdm(range(0, min(1000, len(coco_dataset)))):\n",
    "    image, _ = coco_dataset[i]\n",
    "    \n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(**inputs)\n",
    "    \n",
    "    caption = processor.decode(out[0], skip_special_tokens=True).strip()\n",
    "    \n",
    "    image_id = coco_dataset.ids[i]\n",
    "    results.append({\"image_id\": image_id, \"caption\": caption})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a0e1e8-b182-4e4c-a0ab-b4f9b3d462f3",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9365a6f-22fb-4373-927c-cb13859dabd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./results/coco_results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff17880-b275-413c-af04-e4cac6f4ef9c",
   "metadata": {},
   "source": [
    "## Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a309c82-1bdc-4529-ab93-d5b50fc51bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/gautom/Documents/lavis', '/home/gautom/anaconda3/envs/lavis/lib/python38.zip', '/home/gautom/anaconda3/envs/lavis/lib/python3.8', '/home/gautom/anaconda3/envs/lavis/lib/python3.8/lib-dynload', '', '/home/gautom/.local/lib/python3.8/site-packages', '/home/gautom/anaconda3/envs/lavis/lib/python3.8/site-packages']\n"
     ]
    }
   ],
   "source": [
    "# get pycocoevalfolder\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Add the current directory to the Python path\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "\n",
    "# Verify the path\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1d523f9-0926-42e0-b15a-3d95a43b9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocoevalcap.tokenizer.ptbtokenizer import PTBTokenizer\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "\n",
    "class SimpleCIDErEval:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = PTBTokenizer()\n",
    "        self.cider_scorer = Cider()\n",
    "\n",
    "    def evaluate(self, predictions, references):\n",
    "        # Format the input for the tokenizer\n",
    "        gts = {i: [{'caption': c} for c in refs] for i, refs in enumerate(references)}\n",
    "        res = {i: [{'caption': p}] for i, p in enumerate(predictions)}\n",
    "\n",
    "        # Tokenize\n",
    "        gts_tokenized = self.tokenizer.tokenize(gts)\n",
    "        res_tokenized = self.tokenizer.tokenize(res)\n",
    "\n",
    "        # Compute CIDEr score\n",
    "        score, scores = self.cider_scorer.compute_score(gts_tokenized, res_tokenized)\n",
    "\n",
    "        return score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74a93018-94ff-4b9b-9eba-b3dc01d9635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 61766 tokens at 324387.99 tokens per second.\n",
      "PTBTokenizer tokenized 9242 tokens at 88794.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall CIDEr score: 1.2852764152502318\n"
     ]
    }
   ],
   "source": [
    "coco_dataset = COCODataset(ann_file='./data/coco/annotations/captions_val2017.json',\n",
    "                           img_dir='./data/coco/val2017')\n",
    "\n",
    "f = open('./results/coco_results.json')\n",
    "results = json.load(f)\n",
    "f.close()\n",
    "\n",
    "candidates = [result['caption'] for result in results]\n",
    "references = [coco_dataset.get_captions(result['image_id']) for result in results]\n",
    "\n",
    "# Create evaluator\n",
    "evaluator = SimpleCIDErEval()\n",
    "\n",
    "overall_score, individual_scores = evaluator.evaluate(candidates, references)\n",
    "\n",
    "print(f\"Overall CIDEr score: {overall_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4533abd-f500-41be-b054-ca93072fc93b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 61766 tokens at 336821.45 tokens per second.\n",
      "PTBTokenizer tokenized 9242 tokens at 90941.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CIDEr score: 1.422928345185765\n"
     ]
    }
   ],
   "source": [
    "from cidereval import cider\n",
    "cider_scores = cider(candidates, references)\n",
    "\n",
    "print(f\"Average CIDEr score: {cider_scores['avg_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f74bbf-5aac-4172-9b22-47ec603f94c3",
   "metadata": {},
   "source": [
    "## Replace and test replacement for BLIP-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e304ed3-e8d7-4784-94bd-19a1da82c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Union, Tuple\n",
    "\n",
    "def replace_linear_with_quantized(model: nn.Module, weight_bits: int = 8, activation_bits: int = 8) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Replaces nn.Linear layers in a PyTorch model with NBitLinearDynamic layers.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The PyTorch model to modify.\n",
    "        weight_bits (int): Number of bits for weight quantization. Default is 8.\n",
    "        activation_bits (int): Number of bits for activation quantization. Default is 8.\n",
    "    \n",
    "    Returns:\n",
    "        nn.Module: The modified model with quantized linear layers.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            quantized_linear = NBitLinearDynamic(\n",
    "                in_features=module.in_features,\n",
    "                out_features=module.out_features,\n",
    "                bias=module.bias is not None,\n",
    "                weight_bits=weight_bits,\n",
    "                activation_bits=activation_bits\n",
    "            )\n",
    "            \n",
    "            # Copy the weights and bias\n",
    "            quantized_linear.weight.data = module.weight.data\n",
    "            if module.bias is not None:\n",
    "                quantized_linear.bias.data = module.bias.data\n",
    "            \n",
    "            # Replace the original linear layer with the quantized version\n",
    "            setattr(model, name, quantized_linear)\n",
    "        elif isinstance(module, nn.Module):\n",
    "            # Recursively apply to child modules\n",
    "            setattr(model, name, replace_linear_with_quantized(module, weight_bits, activation_bits))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7817eb0-e1d7-4b7c-8b73-c681fb9f3101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a PyTorch model called 'my_model'\n",
    "quantized_model = replace_linear_with_quantized(model, weight_bits=16, activation_bits=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1629218a-ea53-4687-93b0-b3a846273c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blip2ForConditionalGeneration(\n",
       "  (vision_model): Blip2VisionModel(\n",
       "    (embeddings): Blip2VisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
       "    )\n",
       "    (encoder): Blip2Encoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-38): 39 x Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): NBitLinearDynamic(in_features=1408, out_features=4224, bias=True | w=16, a=32)\n",
       "            (projection): NBitLinearDynamic(in_features=1408, out_features=1408, bias=True | w=16, a=32)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): NBitLinearDynamic(in_features=1408, out_features=6144, bias=True | w=16, a=32)\n",
       "            (fc2): NBitLinearDynamic(in_features=6144, out_features=1408, bias=True | w=16, a=32)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (qformer): Blip2QFormerModel(\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (encoder): Blip2QFormerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=16, a=32)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=16, a=32)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=16, a=32)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=16, a=32)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=16, a=32)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=16, a=32)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=16, a=32)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=16, a=32)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=16, a=32)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=16, a=32)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=16, a=32)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=16, a=32)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=16, a=32)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=16, a=32)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=16, a=32)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=16, a=32)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=16, a=32)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=16, a=32)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=16, a=32)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=16, a=32)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=16, a=32)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=16, a=32)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=16, a=32)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=16, a=32)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=16, a=32)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (language_projection): NBitLinearDynamic(in_features=768, out_features=2560, bias=True | w=16, a=32)\n",
       "  (language_model): OPTForCausalLM(\n",
       "    (model): OPTModel(\n",
       "      (decoder): OPTDecoder(\n",
       "        (embed_tokens): Embedding(50272, 2560, padding_idx=1)\n",
       "        (embed_positions): OPTLearnedPositionalEmbedding(2050, 2560)\n",
       "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): NBitLinearDynamic(in_features=2560, out_features=2560, bias=True | w=16, a=32)\n",
       "              (v_proj): NBitLinearDynamic(in_features=2560, out_features=2560, bias=True | w=16, a=32)\n",
       "              (q_proj): NBitLinearDynamic(in_features=2560, out_features=2560, bias=True | w=16, a=32)\n",
       "              (out_proj): NBitLinearDynamic(in_features=2560, out_features=2560, bias=True | w=16, a=32)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): NBitLinearDynamic(in_features=2560, out_features=10240, bias=True | w=16, a=32)\n",
       "            (fc2): NBitLinearDynamic(in_features=10240, out_features=2560, bias=True | w=16, a=32)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (lm_head): NBitLinearDynamic(in_features=2560, out_features=50272, bias=False | w=16, a=32)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb85c89-2e09-4231-95a0-d1990e0b2168",
   "metadata": {},
   "source": [
    "### Taken from nbitlineardynamic.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22289e5e-05d3-4b5c-8002-bce31ec61758",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Applies N-bit Uniform min-max quantization to both activations and weights for dynamic PTQ\n",
    "\n",
    "@vla, 06/12/2024\n",
    "\n",
    "'''\n",
    "\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Observers compute quantization parameters (scaling factor and zero-point)\n",
    "# TODO: experiment with different observers\n",
    "# from torch.quantization.observer import MinMaxObserver, MovingAverageMinMaxObserver\n",
    "\n",
    "\n",
    "# adapted from: https://pocketflow.github.io/uq_learner/#algorithm\n",
    "def quant(x: Tensor, num_bits):\n",
    "    \n",
    "    # per-sample min/max\n",
    "    # NOTE: granularity could be adjusted \n",
    "    min_val = x.min(dim=-1).values.unsqueeze(-1)\n",
    "    max_val = x.max(dim=-1).values.unsqueeze(-1)\n",
    "    \n",
    "    alpha = max_val - min_val\n",
    "    \n",
    "    # normalize to [0,1]\n",
    "    x = (x-min_val)/alpha\n",
    "    \n",
    "    scale = (2**num_bits - 1)\n",
    "    \n",
    "    # quantize [0,1] --> [-2^B-1, 2^B-1]\n",
    "    result = (scale *x).round()\n",
    "    \n",
    "    # dequantize [-2^B-1, 2^B-1] --> [0,1]\n",
    "    result /= scale\n",
    "    \n",
    "    # back to original scale\n",
    "    result = alpha * result + min_val\n",
    "    \n",
    "    return result\n",
    "    \n",
    "    # # pass input to observer for metric computing\n",
    "    # obs(x)\n",
    "    \n",
    "    # # computed quantization parameters\n",
    "    # s,z = obs.calculate_qparams()\n",
    "    \n",
    "    # # quantize \n",
    "    # result = ((x / s) + z).round()\n",
    "    \n",
    "    # # --> dequantize\n",
    "    # result = (result - z) * s\n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n",
    "class NBitLinearDynamic(nn.Linear):\n",
    "    \"\"\"\n",
    "    Custom linear layer with N-bit uniform quantization.\n",
    "\n",
    "    Args:\n",
    "        dim (int): The input dimension of the layer.\n",
    "        training (bool, optional): Whether the layer is in training mode or not. Defaults to False.\n",
    "        *args: Variable length argument list.\n",
    "        **kwargs: Arbitrary keyword arguments.\n",
    "\n",
    "    Attributes:\n",
    "        dim (int): The input dimension of the layer.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 *kargs,\n",
    "                 weight_bits=8,\n",
    "                 activation_bits=8,\n",
    "                 **kwargs\n",
    "    ):\n",
    "    \n",
    "        # super(NBitLinearDynamic, self).__init__(*kargs, **kwargs)\n",
    "        super().__init__(*kargs, **kwargs)\n",
    "        self.weight_bits     = weight_bits\n",
    "        self.activation_bits = activation_bits\n",
    "        \n",
    "        \n",
    "        # TODO: mess with observer modules instead of computing min,max per sample\n",
    "        # Q_low = -2 ** (self.weight_bits - 1)\n",
    "        # Q_high = 2 ** (self.weight_bits - 1) - 1\n",
    "        # self.weight_observer = MinMaxObserver(quant_min=Q_low, quant_max=Q_high)\n",
    "        \n",
    "        # Q_low = -2 ** (self.activation_bits - 1)\n",
    "        # Q_high = 2 ** (self.activation_bits - 1) - 1\n",
    "        # self.activation_observer = MovingAverageMinMaxObserver(quant_min=Q_low, quant_max=Q_high, is_dynamic=True, averaging_constant=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the NBitLinear layer.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The output tensor.\n",
    "\n",
    "        \"\"\"\n",
    "        w = self.weight\n",
    "        b = self.bias\n",
    "\n",
    "        # STE (Straight-through estimator) trick using detach, not really necessary for just PTQ inference\n",
    "        x_quant = x + (quant(x, self.activation_bits) - x).detach()\n",
    "        w_quant = w + (quant(w, self.weight_bits) - w).detach()\n",
    "        \n",
    "        # quantize bias term if present\n",
    "        if b != None:\n",
    "            b = b + (quant(b, self.weight_bits) - b).detach()\n",
    "        \n",
    "        y = F.linear(x_quant, w_quant, bias = b)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    # print out bitwidth info!\n",
    "    def extra_repr(self) -> str:\n",
    "        return super().extra_repr() + f' | w={self.weight_bits}, a={self.activation_bits}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81df77-8aad-43ac-bd98-78ab9a38ba01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
