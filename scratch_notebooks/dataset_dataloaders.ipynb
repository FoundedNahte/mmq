{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cf77250-15a6-49b4-a87b-c54a31fb1967",
   "metadata": {},
   "source": [
    "# Dataloader Usage Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d60f85-580c-4bda-82a8-b3fda6d65b5d",
   "metadata": {},
   "source": [
    "## Flickr30k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f7a0631-148f-462c-aa8c-655940dc8fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Flickr30k\n",
    "\n",
    "flickr_dataset = Flickr30k(csv_file='./data/flickr30k/results.csv', \n",
    "                          img_dir='./data/flickr30k/images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84d561e7-975f-4c02-af5c-b702cdf0a13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=500x374>,\n",
       " ['Several men in hard hats are operating a giant pulley system .',\n",
       "  'Workers look down from up above on a piece of equipment .',\n",
       "  'Two men working on a machine wearing hard hats .',\n",
       "  'Four men on top of a tall structure .',\n",
       "  'Three men on a large rig .'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flickr_dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116226f5-4722-492c-b2c3-61ccc8336ce8",
   "metadata": {},
   "source": [
    "## COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae094ad7-0998-40ad-86aa-4455fcf033e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import COCODataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f8643f-6087-4c83-91c9-200143193819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_dataset = COCODataset(ann_file='./data/coco/annotations/captions_val2017.json',\n",
    "                           img_dir='./data/coco/val2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6452328e-9b83-41c8-a208-eb14df07f596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=352x230>,\n",
       " ['The dining table near the kitchen has a bowl of fruit on it.',\n",
       "  'A small kitchen has various appliances and a table.',\n",
       "  'The kitchen is clean and ready for us to see.',\n",
       "  'A kitchen and dining area decorated in white.',\n",
       "  'A kitchen that has a bowl of fruit on the table.'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66484b6-99dc-43cb-9cd8-d37cc90ec8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70649f75-aa37-4523-b00a-2402774c4c5b",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a59d795a-914c-4e12-829e-e630b508a317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 32\n",
      "Image shape: torch.Size([32, 3, 224, 224])\n",
      "Number of captions: 5\n",
      "First caption: ['Adorable blond-hair little girl posing for her Daddy while he takes her picture .', 'Three dogs pulling a man in a brown jumpsuit and a baby in a blue snowsuit , on a sled in a snowy forest .', \"Several young children dressed in winter clothes play in the street outside of Stampen 's restaurant with the streetlights on while several adults are standing around .\", 'Male surfer stands on a white surfboard in white shorts and a blue shirt turns to come in as the brown waves splash around him', 'A barefoot boy in shorts and a t-shirt jumps in muddy grass .', 'The child is wearing a blue hat and green jacket while walking through snow .', 'A small group of soccer players are on a soccer field standing around while a player is looked at for injuries .', 'The man in a peach-colored shirt is carrying items on a huge cart .', 'Man in a blue number 78 sports jersey walking down city street past a white SUV', 'Two men are walking down a sidewalk carrying blue netting to the ocean .', 'A man with short brown hair wearing a black jacket and pants on stage singing and pointing into the audience .', 'A large group of cyclists pedal down a road lined with trees .', 'A man in a red hat and blue jacket in a protest is holding up a tablet that talks about God and judgement .', 'A man is flexing his biceps while standing on a rooftop with multiple chimneys in the background .', 'Volleyball team members dressed in red on one side , and team members dressed in yellow and blue on the opposing team , actively blocking a spike while a coach looks on .', 'A man wearing a black top and a woman wearing a purple are riding a suzuki motorbike .', 'A man and woman are looking over a brick wall at a beach scene with a man and a woman embracing at the bottom of the wall .', \"A man is sitting by a large plant waiting to shine a customer 's shoes .\", 'A young boy in a blue shirt is lying on a bed and reading .', 'A young couple embrace and kiss while standing knee deep in the ocean surf .', 'A male corn vendor is selling his grilled corn on a street in a foreign country .', 'The nurse smiles as she gently rubs the tummy of the sleeping child .', 'Silver plane in a blue sky , ready to land with its wheels down , while spectators watch behind a high fence .', 'A man is pulled through the water on a large ski .', 'Four people from a firefighting station in a different country are wearing yellow hard hats while battling a fire .', 'A young lady in a red dress with a guitar is playing and singing in the microphone .', 'A man with a bowtie made out of a dollar and wearing glasses is looking into the camera .', 'A young kid is looking at cat that is trashed with white paint .', \"A man in a striped red shirt leans in his truck 's passenger seat and plays with a jacket sleeve .\", 'A goalie is covering his net while two other hockey players chase after the hockey puck .', 'A young guy playing volleyball wearing a yellow shirt and navy blue shorts and being watched by an audience .', 'A baseball player in a uniform has just thrown a ball with his right hand .']\n",
      "--------------------------------------------------\n",
      "Batch size: 32\n",
      "Image shape: torch.Size([32, 3, 224, 224])\n",
      "Number of captions: 5\n",
      "First caption: ['Two men in a street where 1 is pushing his bike and carrying something in his other hand looking towards the other man as he is saying something .', 'A woman wearing a green shirt is sweeping up a broken potted plant using a red broom and dustpan .', 'Two volleyball players dressed in red and white about to hit a volleyball .', 'Here is a picture of a woman and her husband and child taking a stroll by the parking lot .', 'A man with a dark blue jacket and denim jeans sitting awkwardly on a red bench outside .', 'A woman in the middle of a grassy field during autumn jumps in the air and extends her arms over her head .', 'A bicyclist wearing a black and yellow racing suit rides along a street near a granite building .', 'A young man in shorts and a polo shirt is carrying a garbage bag out of an empty lot with another man following him .', 'A man reads inside of an Asian bakery , and another man is working behind him .', 'A baseball pitcher is halfway through his motion of throwing the ball .', 'a brown dog is running through water carrying a ball in its mouth .', 'One woman is sitting under a loom , another woman is stooping beside it , and is working on the unfinished item .', 'Everyone seems to be in the picture taking mode as a gentlemen on a bicycle in blue paisley shorts poses .', 'A man in a white and black uniform carries luggage and blankets across a sidewalk outside of a red bricked building .', 'Four men are playing dominoes and two of the men are wearing baseball caps .', \"There is a little asian girl with black hair and a white sweater eating a strawberry her eyes are cocked to the right and her fingers are wrapped around the long green vine that 's coming from the fruit .\", 'Two men are fencing , one is wearing a mask with the American flag on it .', 'Young women in a pink top with long brown hair talking to a young man with blond-hair wearing white shirt .', 'A woman with jewels on her face wearing a green sports bra and purple pants is hula hooping in a crowd .', 'An Asian child looking towards something wearing traditional clothing .', 'Two enormous elephants standing on a platform not fenced in , with a lady sitting causally sitting on a bench , in front of them .', 'A group of small school boys wearing uniforms take a break in front of a large monkey statue next to the ocean .', 'Over a dozen people surrounding and taking pictures of two people in all covered head to toe in all silver , in an artistic pose .', 'A man in a red shirt , black overalls and sunglasses plays a guitar .', 'A man is standing with his arms folded looking at something while the person behind him is jumping onto one of the two beds in the room .', 'Five people celebrate victory by opening a bottle of champagne before photographers .', 'A casually dressed man gases confused at a pile of ingredients sitting on a kitchen counter .', 'Two men are sitting on the floor under a staircase playing guitars .', 'One person on a white horse and another person on a dark horse are speaking to a man in a blue coat .', 'On the shore of a lake , a girl jumps for joy in the autumn leaves .', 'A young man with a red handkerchief over his face is the main focus , while people wearing protective security armor are in the background .', 'A person in a dark outfit is walking down a stairwell which contains a shadow of an object .']\n",
      "--------------------------------------------------\n",
      "Batch size: 32\n",
      "Image shape: torch.Size([32, 3, 224, 224])\n",
      "Number of captions: 5\n",
      "First caption: ['a little girl in a walker that looks like she may be up to no good .', 'A line of men wearing white in a martial arts class in the middle of delivering a kick .', 'Little girl walking on rocks near grassy area beside building .', 'Three men are sitting around a bonfire at night with a table of drinks beside them .', 'A group of people are preparing something in the kitchen .', 'a man in a stripy hat is standing in a house built from ice that has a pair of boots in the doorway .', 'A boy in dark pants and green t-shirt rides his bike up a ramp .', 'There is a dog with a Frisbee and a dog jumping up to get a ball in the green grass .', 'A biker is wearing all black gear with buildings and a tree with no leaves nearby .', 'one little white boy wearing a baby blue shirt and has blond short hair , dark eyes and a little gap between his teeth , with his right arm over his heart and left hand holding his right hand .', 'A man wearing a black and white jump suite is jogging down a road .', 'Four women dressed in red shirts are doing the hula dance while several people in the background watch .', \"A woman pauses to look at a window display where an extremely over-sized black , tan , and white beagle that 's licking its nose is framed between two mannequins wearing tan jackets and blue jeans .\", 'Bald male in yellow shirt and orange pants , playing a guitar , hooked to many wires on an electric board , with a yellow stage light beaming off the white wall .', 'A hotel bellboy is pushing a gold colored metal luggage cart filled with various pieces of luggage outside of a fancy hotel .', 'Two brown dogs are fighting and biting each other .', 'A woman wearing a red and white apron is standing next to a wall with the number 333 written on it .', 'A bare chested man with a fierce expression on his face squats on a skateboard beside a furry dog .', 'three people play in the snow with a forest in the background .', 'A rider is being thrown off a bucking white horse with spectators looking on .', 'A woman in a red sweater carries fabric and walks through the mud .', 'Japanese girls in plastic and karate suits to lose weight and there practicing with nun chucks .', 'A busy city street with large buildings that have walkways connecting each other with many orange work vehicles everywhere .', 'A woman in a blue bathing suit lays on a towel in the sand looking in the direction of a group on men .', 'A man in a blue shirt is using his hands to play a large drum .', 'a woman skiing down a snowy mountain with a brown dog on a lesh running with her', 'A boy in an orange and black soccer uniform playing soccer on an artificial turf field , with the ball out in front of him .', 'Two men are carrying children on their backs down the street on a sunny day in a nice neighborhood .', 'Three girls are posing in elegant outfits nearby a tree and a building .', 'An obese male in a blue business shirt and dark pants , walking past a vending machine in a strip mall .', 'A cowboy is viciously thrown about as he attempts to hold on to a horse he is riding in a rodeo competition .', 'A black lab with tags frolicks in the water .']\n",
      "--------------------------------------------------\n",
      "DataLoader is using 16 workers\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Flickr30k\n",
    "from torchvision import transforms\n",
    "import multiprocessing\n",
    "\n",
    "# Define your transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "flickr_dataset = Flickr30k(csv_file='./data/flickr30k/results.csv', \n",
    "                           img_dir='./data/flickr30k/images/',\n",
    "                           transform=transform)\n",
    "\n",
    "# Set up DataLoader parameters\n",
    "batch_size = 32\n",
    "num_workers = multiprocessing.cpu_count()  # Use all available CPU cores\n",
    "\n",
    "# Create the DataLoader\n",
    "data_loader = DataLoader(\n",
    "    flickr_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True  # This can speed up data transfer to GPU\n",
    ")\n",
    "\n",
    "# Demonstrate loading data\n",
    "def process_batch(batch):\n",
    "    images, captions = batch\n",
    "    print(f\"Batch size: {images.shape[0]}\")\n",
    "    print(f\"Image shape: {images.shape}\")\n",
    "    print(f\"Number of captions: {len(captions)}\")\n",
    "    print(f\"First caption: {captions[0]}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Iterate through a few batches\n",
    "for i, batch in enumerate(data_loader):\n",
    "    process_batch(batch)\n",
    "    if i == 2:  # Stop after 3 batches\n",
    "        break\n",
    "Steve Keen\n",
    "print(f\"DataLoader is using {num_workers} workers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ce4a83-2ac2-42e4-afa5-051dbed6f760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautom/anaconda3/envs/lavis/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "# Load BLIP-2 model and processor\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfde8858-2a68-4f1d-8806-0e9f28d54f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blip2Processor:\n",
       "- image_processor: BlipImageProcessor {\n",
       "  \"do_convert_rgb\": true,\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.48145466,\n",
       "    0.4578275,\n",
       "    0.40821073\n",
       "  ],\n",
       "  \"image_processor_type\": \"BlipImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.26862954,\n",
       "    0.26130258,\n",
       "    0.27577711\n",
       "  ],\n",
       "  \"processor_class\": \"Blip2Processor\",\n",
       "  \"resample\": 3,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"height\": 224,\n",
       "    \"width\": 224\n",
       "  }\n",
       "}\n",
       "\n",
       "- tokenizer: GPT2TokenizerFast(name_or_path='Salesforce/blip2-opt-2.7b', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}\n",
       "\n",
       "{\n",
       "  \"processor_class\": \"Blip2Processor\"\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1177da5b-e05a-4de2-b15d-21701849a94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Two young guys with shaggy hair look at their hands while hanging out in the yard .'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flickr_dataset[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0819bfa4-d437-46c0-bb54-47c1058f3ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautom/anaconda3/envs/lavis/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef7f5e332e34ff7840e874ca7a88b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image inputs: dict_keys(['pixel_values'])\n",
      "Text inputs: dict_keys(['input_ids', 'attention_mask'])\n",
      "Image + Text inputs: dict_keys(['pixel_values', 'input_ids', 'attention_mask'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautom/anaconda3/envs/lavis/lib/python3.8/site-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated caption: two men skateboarding in a garden\n",
      "Decoded input: Two young guys with shaggy hair look at their hands while hanging out in the yard.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "from PIL import Image\n",
    "\n",
    "# Initialize the processor and model\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "\n",
    "# Load an example image\n",
    "image = flickr_dataset[0][0]\n",
    "\n",
    "# Example text\n",
    "text = flickr_dataset[0][1][0]\n",
    "\n",
    "# 1. Encoding a single image\n",
    "def encode_image(image):\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    return inputs\n",
    "\n",
    "image_inputs = encode_image(image)\n",
    "print(\"Image inputs:\", image_inputs.keys())\n",
    "\n",
    "# 2. Encoding a single text\n",
    "def encode_text(text):\n",
    "    inputs = processor(text=text, return_tensors=\"pt\")\n",
    "    return inputs\n",
    "\n",
    "text_inputs = encode_text(text)\n",
    "print(\"Text inputs:\", text_inputs.keys())\n",
    "\n",
    "# 3. Encoding a single image + text\n",
    "def encode_image_and_text(image, text):\n",
    "    inputs = processor(images=image, text=text, return_tensors=\"pt\")\n",
    "    return inputs\n",
    "\n",
    "image_text_inputs = encode_image_and_text(image, text)\n",
    "print(\"Image + Text inputs:\", image_text_inputs.keys())\n",
    "\n",
    "# Decoding examples\n",
    "\n",
    "# For image captioning (decoding generated ids)\n",
    "def generate_and_decode_caption(image_inputs):\n",
    "    generated_ids = model.generate(**image_inputs)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "    return generated_text\n",
    "\n",
    "caption = generate_and_decode_caption(image_inputs)\n",
    "print(\"Generated caption:\", caption)\n",
    "\n",
    "# Decoding input ids (if you want to see the tokenized text)\n",
    "def decode_input_ids(input_ids):\n",
    "    decoded_text = processor.decode(input_ids[0], skip_special_tokens=True)\n",
    "    return decoded_text\n",
    "\n",
    "if 'input_ids' in text_inputs:\n",
    "    decoded_input = decode_input_ids(text_inputs['input_ids'])\n",
    "    print(\"Decoded input:\", decoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4839ce-0f22-4e50-b420-7c367a76ff96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
