{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cf77250-15a6-49b4-a87b-c54a31fb1967",
   "metadata": {},
   "source": [
    "# Dataset Usage Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d60f85-580c-4bda-82a8-b3fda6d65b5d",
   "metadata": {},
   "source": [
    "## Flickr30k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f7a0631-148f-462c-aa8c-655940dc8fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Flickr30k\n",
    "\n",
    "flickr_dataset = Flickr30k(csv_file='./data/flickr30k/results.csv', \n",
    "                          img_dir='./data/flickr30k/images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84d561e7-975f-4c02-af5c-b702cdf0a13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=500x374>,\n",
       " ['Several men in hard hats are operating a giant pulley system .',\n",
       "  'Workers look down from up above on a piece of equipment .',\n",
       "  'Two men working on a machine wearing hard hats .',\n",
       "  'Four men on top of a tall structure .',\n",
       "  'Three men on a large rig .'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flickr_dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116226f5-4722-492c-b2c3-61ccc8336ce8",
   "metadata": {},
   "source": [
    "## COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae094ad7-0998-40ad-86aa-4455fcf033e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import COCODataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f8643f-6087-4c83-91c9-200143193819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_dataset = COCODataset(ann_file='./data/coco/annotations/captions_val2017.json',\n",
    "                           img_dir='./data/coco/val2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "693ed229-3410-447e-b13a-bb7eac060d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=352x230>,\n",
       " ['The dining table near the kitchen has a bowl of fruit on it.',\n",
       "  'A small kitchen has various appliances and a table.',\n",
       "  'The kitchen is clean and ready for us to see.',\n",
       "  'A kitchen and dining area decorated in white.',\n",
       "  'A kitchen that has a bowl of fruit on the table.'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205574eb-3167-4ca7-87a6-dedffc41ea9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
